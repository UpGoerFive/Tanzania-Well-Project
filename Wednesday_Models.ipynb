{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import ourfunctions\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import logging\n",
    "\n",
    "#from sklearnex import patch_sklearn\n",
    "#patch_sklearn(verbose=False)\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler, LabelEncoder, FunctionTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, AdaBoostRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import plot_confusion_matrix, recall_score, accuracy_score, precision_score, f1_score\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImPipeline\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn import svm\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('data/Training-set-values.csv')\n",
    "y = pd.read_csv('data/Training-set-labels.csv')\n",
    "\n",
    "X['date_recorded'] = pd.to_datetime(X['date_recorded']).astype(np.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Super basic numeric transformer\n",
    "\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[('imputer', SimpleImputer(strategy='median'))]\n",
    ")\n",
    "\n",
    "numeric_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"numeric\", numeric_transformer, make_column_selector(dtype_include=np.number)),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kNearestNeighbors\n",
    "knn = {'classifier': KNeighborsClassifier(n_jobs=3), 'preprocessor': None}\n",
    "\n",
    "# Logistic Regressoion\n",
    "log_reg_basic = {'classifier': LogisticRegression(C=1e6, n_jobs=3), 'preprocessor': None}\n",
    "\n",
    "# Decision Trees\n",
    "DecisionTrees = {'classifier': DecisionTreeClassifier,'preprocessor': None}\n",
    "# Decision Trees - adjusted\n",
    "DecisionTreesAd = {'classifier': DecisionTreeClassifier(criterion=['gini','entropy'], max_depth=[90,100], min_samples_split=[2,3], class_weight=['balaced']),'preprocessor': numeric_preprocessor}\n",
    "\n",
    "# Random Forest with numeric processor\n",
    "RandomFM_basic = {'classifier': RandomForestClassifier(max_depth=20, min_samples_split=4, n_jobs=3), 'preprocessor': numeric_preprocessor}\n",
    "# Random Forest no processor\n",
    "RandomFM_all_cols = {'classifier': RandomForestClassifier(max_depth=20, min_samples_split=4, n_jobs=3), 'preprocessor': None}\n",
    "# Random Forest default\n",
    "# Included for RandomCVSearch later on\n",
    "RandomFM_default = {'classifier': RandomForestClassifier(n_jobs=3), 'preprocessor': None} \n",
    "\n",
    "# Adaptive Boosting\n",
    "AdaBoost = {'classifier': AdaBoostClassifier(), 'preprocessor': numeric_preprocessor}\n",
    "# Gradient Boost\n",
    "GradBoost = {'classifier': GradientBoostingClassifier,'preprocessor': numeric_preprocessor}\n",
    "# XGradient Boosting\n",
    "XGBoost = {'classifier': XGBRegressor(objective='reg:squarederror'), 'preprocessor': numeric_preprocessor}\n",
    "# CatBoost \n",
    "CatBoost = {'classifier': CatBoostClassifier(max_depth=3),'preprocessor': numeric_preprocessor}\n",
    "\n",
    "# Support Vector Machine\n",
    "SVM = {'classifier': svm.SVC,'preprocessor': numeric_preprocessor}\n",
    "\n",
    "models = {'knn': knn, \n",
    "    'log_reg_basic': log_reg_basic, \n",
    "    'DecisionTree': DecisionTrees,\n",
    "    'DecisionTreeAd': DecisionTreesAd,\n",
    "    'RandomFM_basic': RandomFM_basic, \n",
    "    'RandomFM_all_cols': RandomFM_all_cols, \n",
    "    'RandomFM_default': RandomFM_default,\n",
    "    'AdaBoost': AdaBoost,\n",
    "    'GradBoost': GradBoost,\n",
    "    'XGBoost': XGBoost,\n",
    "    'CatBoost': CatBoost,\n",
    "    \"SVM\": SVM\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_run = ourfunctions.Modeler(models, X=X, y=y)\n",
    "\n",
    "# after the model_run object is created so we can add onto the default preprocessor.\n",
    "log_reg_regularized = {'classifier': LogisticRegression(n_jobs=3), 'preprocessor': model_run.create_default_prep(num_add=[('scaling', StandardScaler())])}\n",
    "model_run.add_model('log_reg_regularized', log_reg_regularized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search parameters and kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kNN_params = \n",
    "\n",
    "LogRegRCV_params = dict(penalty=['l1', 'l2', 'elasticnet'],\n",
    "                        C=stats.uniform(loc=1, scale=10),\n",
    "                        max_iter=list(range(100,400)))\n",
    "\n",
    "DecisionTree_params = dict(criterion=['gini', 'entropy'],\n",
    "                        max_depth = list(range(20,50)),\n",
    "                        min_samples_split = list(range(2, 10)),\n",
    "                        class_weight = 'balanced')\n",
    "\n",
    "RandForestRCV_params = dict(n_estimators=list(range(100,300)),\n",
    "                            criterion=['gini', 'entropy'],\n",
    "                            max_depth = list(range(20,50)),\n",
    "                            min_samples_split = list(range(2, 10)))\n",
    "\n",
    "AdaBoost_params = dict(n_estimators=[10, 50, 100, 500],\n",
    "                        learning_rate=[0.001, 0.01, 0.1, 1.0])\n",
    "\n",
    "GradBoost_params = dict(n_estimators=[10, 30, 100],\n",
    "                    criterion=['friedman_mse', 'squared_error'],\n",
    "                    max_depth=[2, 6, 10],\n",
    "                    min_samples_split=[5, 10],\n",
    "                    min_samples_leaf=[3, 6])\n",
    "\n",
    "XGBoost_params = dict(learning_rate =[0.01, 0.1], \n",
    "                    n_estimators=[100, 200, 500],\n",
    "                    max_depth=[2, 4, 6, 8],\n",
    "                    colsample_bytree=[0.6, 0.8],\n",
    "                    objective= 'binary:logistic')\n",
    "\n",
    "CatBoost_params = dict(max_depth =[3,4,5],\n",
    "                        n_estimators = [100,200,300])\n",
    "\n",
    "SVM_params = dict(C=[0.1,1, 10, 100], \n",
    "                gamma=[1,0.1,0.01,0.001],\n",
    "                kernel=['rbf', 'poly', 'sigmoid'])\n",
    "\n",
    "search_options = {'n_jobs': 3, 'random_state': 9280210, 'n_iter': 20}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_run.hyper_search('log_reg_regularized', params=LogRegRCV_params, searcher_kwargs=search_options, set_to_train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_run.hyper_search('kNN', params=kNN_params, searcher_kwargs=search_options, set_to_train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The only valid preset for class_weight is \"balanced\". Given \"c\".",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-ce7a2070d44d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_run\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyper_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DecisionTreeAd'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDecisionTree_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msearcher_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msearch_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_to_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/Tanzania-Well-Project/ourfunctions.py\u001b[0m in \u001b[0;36mhyper_search\u001b[0;34m(self, name, searcher, params, searcher_kwargs, print, set_to_train)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mX_train_processed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_models\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'preprocessor'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_X_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m         \u001b[0msearch_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_processed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_y_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"For model {name}, {searcher} with{params} produced:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Params: {search_object.best_params_}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    763\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    888\u001b[0m         \"\"\"\n\u001b[1;32m    889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 890\u001b[0;31m         super().fit(\n\u001b[0m\u001b[1;32m    891\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 expanded_class_weight = compute_sample_weight(\n\u001b[0m\u001b[1;32m    200\u001b[0m                     self.class_weight, y_original)\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/utils/class_weight.py\u001b[0m in \u001b[0;36mcompute_sample_weight\u001b[0;34m(class_weight, y, indices)\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mclass_weight\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'balanced'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             raise ValueError('The only valid preset for class_weight is '\n\u001b[0m\u001b[1;32m    123\u001b[0m                              '\"balanced\". Given \"%s\".' % class_weight)\n\u001b[1;32m    124\u001b[0m     elif (indices is not None and\n",
      "\u001b[0;31mValueError\u001b[0m: The only valid preset for class_weight is \"balanced\". Given \"c\"."
     ]
    }
   ],
   "source": [
    "model_run.hyper_search('DecisionTreeAd', params=DecisionTree_params, searcher_kwargs=search_options, set_to_train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_run.hyper_search('RandomFM_default', params=RandForestRCV_params, searcher_kwargs=search_options, set_to_train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/valeriaviscarra/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/model_selection/_search.py:278: UserWarning: The total space of parameters 16 is smaller than n_iter=20. Running 16 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_run.hyper_search('AdaBoost', params=AdaBoost_params, searcher_kwargs=search_options, set_to_train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot clone object. You should provide an instance of scikit-learn estimator instead of a class.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-2fb2f0de16ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_run\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyper_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GradBoost'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mGradBoost_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msearcher_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msearch_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_to_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/Tanzania-Well-Project/ourfunctions.py\u001b[0m in \u001b[0;36mhyper_search\u001b[0;34m(self, name, searcher, params, searcher_kwargs, print, set_to_train)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mX_train_processed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_models\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'preprocessor'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_X_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m         \u001b[0msearch_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_processed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_y_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"For model {name}, {searcher} with{params} produced:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Params: {search_object.best_params_}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    679\u001b[0m         \u001b[0mn_splits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_n_splits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m         \u001b[0mbase_estimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m         parallel = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mclone\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m                 raise TypeError(\"Cannot clone object. \" +\n\u001b[0m\u001b[1;32m     75\u001b[0m                                 \u001b[0;34m\"You should provide an instance of \"\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m                                 \"scikit-learn estimator instead of a class.\")\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot clone object. You should provide an instance of scikit-learn estimator instead of a class."
     ]
    }
   ],
   "source": [
    "model_run.hyper_search('GradBoost', params=GradBoost_params, searcher_kwargs=search_options, set_to_train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "XGBoostError",
     "evalue": "[19:19:14] /Users/runner/miniforge3/conda-bld/xgboost_1598185652448/work/src/objective/objective.cc:26: Unknown objective function: `c`\nObjective candidate: survival:aft\nObjective candidate: binary:hinge\nObjective candidate: multi:softmax\nObjective candidate: multi:softprob\nObjective candidate: rank:pairwise\nObjective candidate: rank:ndcg\nObjective candidate: rank:map\nObjective candidate: reg:squarederror\nObjective candidate: reg:squaredlogerror\nObjective candidate: reg:logistic\nObjective candidate: reg:pseudohubererror\nObjective candidate: binary:logistic\nObjective candidate: binary:logitraw\nObjective candidate: reg:linear\nObjective candidate: count:poisson\nObjective candidate: survival:cox\nObjective candidate: reg:gamma\nObjective candidate: reg:tweedie\n\nStack trace:\n  [bt] (0) 1   libxgboost.dylib                    0x0000000170c5ce4e dmlc::LogMessageFatal::~LogMessageFatal() + 110\n  [bt] (1) 2   libxgboost.dylib                    0x0000000170d48257 xgboost::ObjFunction::Create(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, xgboost::GenericParameter const*) + 759\n  [bt] (2) 3   libxgboost.dylib                    0x0000000170d0ac76 xgboost::LearnerConfiguration::ConfigureObjective(xgboost::LearnerTrainParam const&, std::__1::vector<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > >*) + 1926\n  [bt] (3) 4   libxgboost.dylib                    0x0000000170cff90f xgboost::LearnerConfiguration::Configure() + 1327\n  [bt] (4) 5   libxgboost.dylib                    0x0000000170cffea7 xgboost::LearnerImpl::UpdateOneIter(int, std::__1::shared_ptr<xgboost::DMatrix>) + 119\n  [bt] (5) 6   libxgboost.dylib                    0x0000000170c54c9a XGBoosterUpdateOneIter + 154\n  [bt] (6) 7   libffi.7.dylib                      0x000000010b68aead ffi_call_unix64 + 85\n  [bt] (7) 8   ???                                 0x0000000305c0cf10 0x0 + 12981423888\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-11e648b23166>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_run\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyper_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'XGBoost'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mXGBoost_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msearcher_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msearch_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_to_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/Tanzania-Well-Project/ourfunctions.py\u001b[0m in \u001b[0;36mhyper_search\u001b[0;34m(self, name, searcher, params, searcher_kwargs, print, set_to_train)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mX_train_processed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_models\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'preprocessor'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_X_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m         \u001b[0msearch_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_processed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_y_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"For model {name}, {searcher} with{params} produced:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Params: {search_object.best_params_}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    763\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[1;32m    540\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'eval_metric'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0meval_metric\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m         self._Booster = train(params, train_dmatrix,\n\u001b[0m\u001b[1;32m    543\u001b[0m                               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_num_boosting_rounds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m                               \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_evaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m     return _train_internal(params, dtrain,\n\u001b[0m\u001b[1;32m    209\u001b[0m                            \u001b[0mnum_boost_round\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_boost_round\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1159\u001b[0;31m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001b[0m\u001b[1;32m   1160\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1161\u001b[0m                                                     dtrain.handle))\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36m_check_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \"\"\"\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mXGBoostError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBGetLastError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mXGBoostError\u001b[0m: [19:19:14] /Users/runner/miniforge3/conda-bld/xgboost_1598185652448/work/src/objective/objective.cc:26: Unknown objective function: `c`\nObjective candidate: survival:aft\nObjective candidate: binary:hinge\nObjective candidate: multi:softmax\nObjective candidate: multi:softprob\nObjective candidate: rank:pairwise\nObjective candidate: rank:ndcg\nObjective candidate: rank:map\nObjective candidate: reg:squarederror\nObjective candidate: reg:squaredlogerror\nObjective candidate: reg:logistic\nObjective candidate: reg:pseudohubererror\nObjective candidate: binary:logistic\nObjective candidate: binary:logitraw\nObjective candidate: reg:linear\nObjective candidate: count:poisson\nObjective candidate: survival:cox\nObjective candidate: reg:gamma\nObjective candidate: reg:tweedie\n\nStack trace:\n  [bt] (0) 1   libxgboost.dylib                    0x0000000170c5ce4e dmlc::LogMessageFatal::~LogMessageFatal() + 110\n  [bt] (1) 2   libxgboost.dylib                    0x0000000170d48257 xgboost::ObjFunction::Create(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, xgboost::GenericParameter const*) + 759\n  [bt] (2) 3   libxgboost.dylib                    0x0000000170d0ac76 xgboost::LearnerConfiguration::ConfigureObjective(xgboost::LearnerTrainParam const&, std::__1::vector<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > >*) + 1926\n  [bt] (3) 4   libxgboost.dylib                    0x0000000170cff90f xgboost::LearnerConfiguration::Configure() + 1327\n  [bt] (4) 5   libxgboost.dylib                    0x0000000170cffea7 xgboost::LearnerImpl::UpdateOneIter(int, std::__1::shared_ptr<xgboost::DMatrix>) + 119\n  [bt] (5) 6   libxgboost.dylib                    0x0000000170c54c9a XGBoosterUpdateOneIter + 154\n  [bt] (6) 7   libffi.7.dylib                      0x000000010b68aead ffi_call_unix64 + 85\n  [bt] (7) 8   ???                                 0x0000000305c0cf10 0x0 + 12981423888\n\n"
     ]
    }
   ],
   "source": [
    "model_run.hyper_search('XGBoost', params=XGBoost_params, searcher_kwargs=search_options, set_to_train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/valeriaviscarra/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/model_selection/_search.py:278: UserWarning: The total space of parameters 9 is smaller than n_iter=20. Running 9 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.265612\n",
      "0:\tlearn: 0.9862021\ttotal: 68.7ms\tremaining: 20.5s\n",
      "1:\tlearn: 0.9216414\ttotal: 77.4ms\tremaining: 11.5s\n",
      "2:\tlearn: 0.8824521\ttotal: 83.4ms\tremaining: 8.26s\n",
      "3:\tlearn: 0.8555248\ttotal: 91.7ms\tremaining: 6.79s\n",
      "4:\tlearn: 0.8364673\ttotal: 97.2ms\tremaining: 5.73s\n",
      "5:\tlearn: 0.8218166\ttotal: 102ms\tremaining: 5s\n",
      "6:\tlearn: 0.8129340\ttotal: 107ms\tremaining: 4.5s\n",
      "7:\tlearn: 0.8058792\ttotal: 113ms\tremaining: 4.13s\n",
      "8:\tlearn: 0.7989142\ttotal: 119ms\tremaining: 3.86s\n",
      "9:\tlearn: 0.7937780\ttotal: 125ms\tremaining: 3.63s\n",
      "10:\tlearn: 0.7907538\ttotal: 131ms\tremaining: 3.44s\n",
      "11:\tlearn: 0.7854812\ttotal: 136ms\tremaining: 3.27s\n",
      "12:\tlearn: 0.7833159\ttotal: 142ms\tremaining: 3.13s\n",
      "13:\tlearn: 0.7807781\ttotal: 147ms\tremaining: 3.01s\n",
      "14:\tlearn: 0.7768205\ttotal: 153ms\tremaining: 2.91s\n",
      "15:\tlearn: 0.7742835\ttotal: 159ms\tremaining: 2.81s\n",
      "16:\tlearn: 0.7717098\ttotal: 166ms\tremaining: 2.76s\n",
      "17:\tlearn: 0.7701826\ttotal: 171ms\tremaining: 2.69s\n",
      "18:\tlearn: 0.7680539\ttotal: 179ms\tremaining: 2.65s\n",
      "19:\tlearn: 0.7654467\ttotal: 185ms\tremaining: 2.59s\n",
      "20:\tlearn: 0.7643011\ttotal: 191ms\tremaining: 2.53s\n",
      "21:\tlearn: 0.7621080\ttotal: 197ms\tremaining: 2.49s\n",
      "22:\tlearn: 0.7607630\ttotal: 203ms\tremaining: 2.44s\n",
      "23:\tlearn: 0.7599562\ttotal: 208ms\tremaining: 2.39s\n",
      "24:\tlearn: 0.7587362\ttotal: 229ms\tremaining: 2.52s\n",
      "25:\tlearn: 0.7570620\ttotal: 235ms\tremaining: 2.48s\n",
      "26:\tlearn: 0.7555946\ttotal: 242ms\tremaining: 2.45s\n",
      "27:\tlearn: 0.7547239\ttotal: 248ms\tremaining: 2.41s\n",
      "28:\tlearn: 0.7524917\ttotal: 254ms\tremaining: 2.38s\n",
      "29:\tlearn: 0.7519444\ttotal: 260ms\tremaining: 2.33s\n",
      "30:\tlearn: 0.7502119\ttotal: 266ms\tremaining: 2.31s\n",
      "31:\tlearn: 0.7493089\ttotal: 271ms\tremaining: 2.27s\n",
      "32:\tlearn: 0.7483707\ttotal: 277ms\tremaining: 2.24s\n",
      "33:\tlearn: 0.7474882\ttotal: 282ms\tremaining: 2.21s\n",
      "34:\tlearn: 0.7469998\ttotal: 287ms\tremaining: 2.18s\n",
      "35:\tlearn: 0.7462165\ttotal: 293ms\tremaining: 2.15s\n",
      "36:\tlearn: 0.7454923\ttotal: 298ms\tremaining: 2.12s\n",
      "37:\tlearn: 0.7449400\ttotal: 304ms\tremaining: 2.09s\n",
      "38:\tlearn: 0.7441302\ttotal: 309ms\tremaining: 2.07s\n",
      "39:\tlearn: 0.7433239\ttotal: 316ms\tremaining: 2.06s\n",
      "40:\tlearn: 0.7427218\ttotal: 322ms\tremaining: 2.03s\n",
      "41:\tlearn: 0.7421874\ttotal: 327ms\tremaining: 2.01s\n",
      "42:\tlearn: 0.7416821\ttotal: 333ms\tremaining: 1.99s\n",
      "43:\tlearn: 0.7410810\ttotal: 346ms\tremaining: 2.01s\n",
      "44:\tlearn: 0.7402066\ttotal: 351ms\tremaining: 1.99s\n",
      "45:\tlearn: 0.7397162\ttotal: 357ms\tremaining: 1.97s\n",
      "46:\tlearn: 0.7389758\ttotal: 363ms\tremaining: 1.96s\n",
      "47:\tlearn: 0.7376477\ttotal: 370ms\tremaining: 1.94s\n",
      "48:\tlearn: 0.7358570\ttotal: 375ms\tremaining: 1.92s\n",
      "49:\tlearn: 0.7345929\ttotal: 381ms\tremaining: 1.91s\n",
      "50:\tlearn: 0.7341370\ttotal: 387ms\tremaining: 1.89s\n",
      "51:\tlearn: 0.7335331\ttotal: 392ms\tremaining: 1.87s\n",
      "52:\tlearn: 0.7328099\ttotal: 397ms\tremaining: 1.85s\n",
      "53:\tlearn: 0.7319877\ttotal: 403ms\tremaining: 1.84s\n",
      "54:\tlearn: 0.7313519\ttotal: 410ms\tremaining: 1.82s\n",
      "55:\tlearn: 0.7308233\ttotal: 416ms\tremaining: 1.81s\n",
      "56:\tlearn: 0.7299381\ttotal: 422ms\tremaining: 1.8s\n",
      "57:\tlearn: 0.7292388\ttotal: 430ms\tremaining: 1.79s\n",
      "58:\tlearn: 0.7285104\ttotal: 436ms\tremaining: 1.78s\n",
      "59:\tlearn: 0.7278373\ttotal: 442ms\tremaining: 1.77s\n",
      "60:\tlearn: 0.7272494\ttotal: 447ms\tremaining: 1.75s\n",
      "61:\tlearn: 0.7268308\ttotal: 453ms\tremaining: 1.74s\n",
      "62:\tlearn: 0.7259207\ttotal: 459ms\tremaining: 1.73s\n",
      "63:\tlearn: 0.7250652\ttotal: 466ms\tremaining: 1.72s\n",
      "64:\tlearn: 0.7245775\ttotal: 472ms\tremaining: 1.7s\n",
      "65:\tlearn: 0.7242131\ttotal: 478ms\tremaining: 1.7s\n",
      "66:\tlearn: 0.7237149\ttotal: 484ms\tremaining: 1.68s\n",
      "67:\tlearn: 0.7228607\ttotal: 490ms\tremaining: 1.67s\n",
      "68:\tlearn: 0.7216970\ttotal: 495ms\tremaining: 1.66s\n",
      "69:\tlearn: 0.7208336\ttotal: 501ms\tremaining: 1.64s\n",
      "70:\tlearn: 0.7200949\ttotal: 507ms\tremaining: 1.63s\n",
      "71:\tlearn: 0.7199579\ttotal: 512ms\tremaining: 1.62s\n",
      "72:\tlearn: 0.7196629\ttotal: 518ms\tremaining: 1.61s\n",
      "73:\tlearn: 0.7189871\ttotal: 523ms\tremaining: 1.6s\n",
      "74:\tlearn: 0.7185068\ttotal: 528ms\tremaining: 1.58s\n",
      "75:\tlearn: 0.7175748\ttotal: 535ms\tremaining: 1.58s\n",
      "76:\tlearn: 0.7167162\ttotal: 543ms\tremaining: 1.57s\n",
      "77:\tlearn: 0.7161447\ttotal: 549ms\tremaining: 1.56s\n",
      "78:\tlearn: 0.7157405\ttotal: 554ms\tremaining: 1.55s\n",
      "79:\tlearn: 0.7155016\ttotal: 559ms\tremaining: 1.54s\n",
      "80:\tlearn: 0.7152352\ttotal: 565ms\tremaining: 1.53s\n",
      "81:\tlearn: 0.7144699\ttotal: 571ms\tremaining: 1.52s\n",
      "82:\tlearn: 0.7139931\ttotal: 576ms\tremaining: 1.5s\n",
      "83:\tlearn: 0.7136669\ttotal: 581ms\tremaining: 1.5s\n",
      "84:\tlearn: 0.7132828\ttotal: 588ms\tremaining: 1.49s\n",
      "85:\tlearn: 0.7130521\ttotal: 593ms\tremaining: 1.48s\n",
      "86:\tlearn: 0.7128256\ttotal: 598ms\tremaining: 1.47s\n",
      "87:\tlearn: 0.7122340\ttotal: 605ms\tremaining: 1.46s\n",
      "88:\tlearn: 0.7117152\ttotal: 611ms\tremaining: 1.45s\n",
      "89:\tlearn: 0.7111235\ttotal: 617ms\tremaining: 1.44s\n",
      "90:\tlearn: 0.7105650\ttotal: 626ms\tremaining: 1.44s\n",
      "91:\tlearn: 0.7101654\ttotal: 632ms\tremaining: 1.43s\n",
      "92:\tlearn: 0.7097073\ttotal: 638ms\tremaining: 1.42s\n",
      "93:\tlearn: 0.7093692\ttotal: 649ms\tremaining: 1.42s\n",
      "94:\tlearn: 0.7087599\ttotal: 657ms\tremaining: 1.42s\n",
      "95:\tlearn: 0.7083993\ttotal: 665ms\tremaining: 1.41s\n",
      "96:\tlearn: 0.7079316\ttotal: 671ms\tremaining: 1.4s\n",
      "97:\tlearn: 0.7075359\ttotal: 676ms\tremaining: 1.39s\n",
      "98:\tlearn: 0.7069493\ttotal: 683ms\tremaining: 1.39s\n",
      "99:\tlearn: 0.7066890\ttotal: 689ms\tremaining: 1.38s\n",
      "100:\tlearn: 0.7062836\ttotal: 695ms\tremaining: 1.37s\n",
      "101:\tlearn: 0.7057782\ttotal: 702ms\tremaining: 1.36s\n",
      "102:\tlearn: 0.7052138\ttotal: 707ms\tremaining: 1.35s\n",
      "103:\tlearn: 0.7048717\ttotal: 713ms\tremaining: 1.34s\n",
      "104:\tlearn: 0.7043149\ttotal: 718ms\tremaining: 1.33s\n",
      "105:\tlearn: 0.7037837\ttotal: 724ms\tremaining: 1.32s\n",
      "106:\tlearn: 0.7035477\ttotal: 729ms\tremaining: 1.31s\n",
      "107:\tlearn: 0.7031474\ttotal: 736ms\tremaining: 1.31s\n",
      "108:\tlearn: 0.7028812\ttotal: 744ms\tremaining: 1.3s\n",
      "109:\tlearn: 0.7024816\ttotal: 749ms\tremaining: 1.29s\n",
      "110:\tlearn: 0.7023014\ttotal: 756ms\tremaining: 1.29s\n",
      "111:\tlearn: 0.7020343\ttotal: 763ms\tremaining: 1.28s\n",
      "112:\tlearn: 0.7014935\ttotal: 769ms\tremaining: 1.27s\n",
      "113:\tlearn: 0.7008822\ttotal: 775ms\tremaining: 1.26s\n",
      "114:\tlearn: 0.7001683\ttotal: 781ms\tremaining: 1.25s\n",
      "115:\tlearn: 0.6997198\ttotal: 786ms\tremaining: 1.25s\n",
      "116:\tlearn: 0.6994358\ttotal: 792ms\tremaining: 1.24s\n",
      "117:\tlearn: 0.6989996\ttotal: 798ms\tremaining: 1.23s\n",
      "118:\tlearn: 0.6982237\ttotal: 804ms\tremaining: 1.22s\n",
      "119:\tlearn: 0.6979792\ttotal: 811ms\tremaining: 1.22s\n",
      "120:\tlearn: 0.6974945\ttotal: 816ms\tremaining: 1.21s\n",
      "121:\tlearn: 0.6973029\ttotal: 822ms\tremaining: 1.2s\n",
      "122:\tlearn: 0.6965589\ttotal: 828ms\tremaining: 1.19s\n",
      "123:\tlearn: 0.6958777\ttotal: 835ms\tremaining: 1.18s\n",
      "124:\tlearn: 0.6954549\ttotal: 841ms\tremaining: 1.18s\n",
      "125:\tlearn: 0.6948730\ttotal: 846ms\tremaining: 1.17s\n",
      "126:\tlearn: 0.6944926\ttotal: 852ms\tremaining: 1.16s\n",
      "127:\tlearn: 0.6942409\ttotal: 858ms\tremaining: 1.15s\n",
      "128:\tlearn: 0.6938831\ttotal: 863ms\tremaining: 1.14s\n",
      "129:\tlearn: 0.6933897\ttotal: 869ms\tremaining: 1.14s\n",
      "130:\tlearn: 0.6929890\ttotal: 875ms\tremaining: 1.13s\n",
      "131:\tlearn: 0.6927727\ttotal: 881ms\tremaining: 1.12s\n",
      "132:\tlearn: 0.6925038\ttotal: 887ms\tremaining: 1.11s\n",
      "133:\tlearn: 0.6922629\ttotal: 897ms\tremaining: 1.11s\n",
      "134:\tlearn: 0.6921055\ttotal: 903ms\tremaining: 1.1s\n",
      "135:\tlearn: 0.6915043\ttotal: 909ms\tremaining: 1.09s\n",
      "136:\tlearn: 0.6911007\ttotal: 920ms\tremaining: 1.09s\n",
      "137:\tlearn: 0.6909734\ttotal: 926ms\tremaining: 1.09s\n",
      "138:\tlearn: 0.6907828\ttotal: 932ms\tremaining: 1.08s\n",
      "139:\tlearn: 0.6903439\ttotal: 942ms\tremaining: 1.08s\n",
      "140:\tlearn: 0.6899446\ttotal: 948ms\tremaining: 1.07s\n",
      "141:\tlearn: 0.6897336\ttotal: 953ms\tremaining: 1.06s\n",
      "142:\tlearn: 0.6890028\ttotal: 959ms\tremaining: 1.05s\n",
      "143:\tlearn: 0.6888017\ttotal: 965ms\tremaining: 1.04s\n",
      "144:\tlearn: 0.6885661\ttotal: 971ms\tremaining: 1.04s\n",
      "145:\tlearn: 0.6883078\ttotal: 981ms\tremaining: 1.03s\n",
      "146:\tlearn: 0.6880787\ttotal: 987ms\tremaining: 1.03s\n",
      "147:\tlearn: 0.6879440\ttotal: 993ms\tremaining: 1.02s\n",
      "148:\tlearn: 0.6877710\ttotal: 999ms\tremaining: 1.01s\n",
      "149:\tlearn: 0.6874680\ttotal: 1.01s\tremaining: 1.01s\n",
      "150:\tlearn: 0.6868596\ttotal: 1.01s\tremaining: 999ms\n",
      "151:\tlearn: 0.6866838\ttotal: 1.02s\tremaining: 992ms\n",
      "152:\tlearn: 0.6865547\ttotal: 1.02s\tremaining: 984ms\n",
      "153:\tlearn: 0.6863040\ttotal: 1.03s\tremaining: 977ms\n",
      "154:\tlearn: 0.6860710\ttotal: 1.04s\tremaining: 970ms\n",
      "155:\tlearn: 0.6858833\ttotal: 1.04s\tremaining: 961ms\n",
      "156:\tlearn: 0.6856223\ttotal: 1.05s\tremaining: 954ms\n",
      "157:\tlearn: 0.6855290\ttotal: 1.05s\tremaining: 946ms\n",
      "158:\tlearn: 0.6852198\ttotal: 1.06s\tremaining: 941ms\n",
      "159:\tlearn: 0.6850933\ttotal: 1.07s\tremaining: 934ms\n",
      "160:\tlearn: 0.6847890\ttotal: 1.07s\tremaining: 926ms\n",
      "161:\tlearn: 0.6844359\ttotal: 1.08s\tremaining: 919ms\n",
      "162:\tlearn: 0.6842905\ttotal: 1.08s\tremaining: 911ms\n",
      "163:\tlearn: 0.6837388\ttotal: 1.09s\tremaining: 904ms\n",
      "164:\tlearn: 0.6835274\ttotal: 1.09s\tremaining: 896ms\n",
      "165:\tlearn: 0.6830261\ttotal: 1.1s\tremaining: 888ms\n",
      "166:\tlearn: 0.6829305\ttotal: 1.1s\tremaining: 881ms\n",
      "167:\tlearn: 0.6824248\ttotal: 1.11s\tremaining: 874ms\n",
      "168:\tlearn: 0.6822852\ttotal: 1.12s\tremaining: 867ms\n",
      "169:\tlearn: 0.6821000\ttotal: 1.12s\tremaining: 859ms\n",
      "170:\tlearn: 0.6819819\ttotal: 1.13s\tremaining: 852ms\n",
      "171:\tlearn: 0.6818358\ttotal: 1.14s\tremaining: 845ms\n",
      "172:\tlearn: 0.6815077\ttotal: 1.14s\tremaining: 838ms\n",
      "173:\tlearn: 0.6808999\ttotal: 1.15s\tremaining: 830ms\n",
      "174:\tlearn: 0.6803657\ttotal: 1.15s\tremaining: 823ms\n",
      "175:\tlearn: 0.6800620\ttotal: 1.16s\tremaining: 816ms\n",
      "176:\tlearn: 0.6797150\ttotal: 1.16s\tremaining: 809ms\n",
      "177:\tlearn: 0.6793064\ttotal: 1.17s\tremaining: 802ms\n",
      "178:\tlearn: 0.6791988\ttotal: 1.18s\tremaining: 795ms\n",
      "179:\tlearn: 0.6789792\ttotal: 1.18s\tremaining: 788ms\n",
      "180:\tlearn: 0.6787075\ttotal: 1.19s\tremaining: 781ms\n",
      "181:\tlearn: 0.6785000\ttotal: 1.19s\tremaining: 774ms\n",
      "182:\tlearn: 0.6782578\ttotal: 1.2s\tremaining: 767ms\n",
      "183:\tlearn: 0.6780926\ttotal: 1.21s\tremaining: 760ms\n",
      "184:\tlearn: 0.6779609\ttotal: 1.21s\tremaining: 753ms\n",
      "185:\tlearn: 0.6777202\ttotal: 1.22s\tremaining: 747ms\n",
      "186:\tlearn: 0.6774143\ttotal: 1.22s\tremaining: 740ms\n",
      "187:\tlearn: 0.6770613\ttotal: 1.23s\tremaining: 734ms\n",
      "188:\tlearn: 0.6769468\ttotal: 1.24s\tremaining: 727ms\n",
      "189:\tlearn: 0.6766225\ttotal: 1.24s\tremaining: 720ms\n",
      "190:\tlearn: 0.6763521\ttotal: 1.25s\tremaining: 712ms\n",
      "191:\tlearn: 0.6759093\ttotal: 1.25s\tremaining: 706ms\n",
      "192:\tlearn: 0.6756899\ttotal: 1.26s\tremaining: 698ms\n",
      "193:\tlearn: 0.6754265\ttotal: 1.26s\tremaining: 691ms\n",
      "194:\tlearn: 0.6752286\ttotal: 1.27s\tremaining: 685ms\n",
      "195:\tlearn: 0.6750735\ttotal: 1.28s\tremaining: 678ms\n",
      "196:\tlearn: 0.6749758\ttotal: 1.28s\tremaining: 671ms\n",
      "197:\tlearn: 0.6747822\ttotal: 1.29s\tremaining: 664ms\n",
      "198:\tlearn: 0.6745848\ttotal: 1.29s\tremaining: 657ms\n",
      "199:\tlearn: 0.6743064\ttotal: 1.3s\tremaining: 650ms\n",
      "200:\tlearn: 0.6740929\ttotal: 1.3s\tremaining: 643ms\n",
      "201:\tlearn: 0.6738261\ttotal: 1.32s\tremaining: 640ms\n",
      "202:\tlearn: 0.6736186\ttotal: 1.32s\tremaining: 633ms\n",
      "203:\tlearn: 0.6734258\ttotal: 1.33s\tremaining: 626ms\n",
      "204:\tlearn: 0.6731006\ttotal: 1.33s\tremaining: 619ms\n",
      "205:\tlearn: 0.6729178\ttotal: 1.34s\tremaining: 612ms\n",
      "206:\tlearn: 0.6728008\ttotal: 1.35s\tremaining: 605ms\n",
      "207:\tlearn: 0.6726040\ttotal: 1.35s\tremaining: 598ms\n",
      "208:\tlearn: 0.6722880\ttotal: 1.36s\tremaining: 591ms\n",
      "209:\tlearn: 0.6719992\ttotal: 1.36s\tremaining: 585ms\n",
      "210:\tlearn: 0.6717141\ttotal: 1.37s\tremaining: 578ms\n",
      "211:\tlearn: 0.6715837\ttotal: 1.38s\tremaining: 571ms\n",
      "212:\tlearn: 0.6713350\ttotal: 1.38s\tremaining: 564ms\n",
      "213:\tlearn: 0.6711283\ttotal: 1.39s\tremaining: 560ms\n",
      "214:\tlearn: 0.6708570\ttotal: 1.4s\tremaining: 553ms\n",
      "215:\tlearn: 0.6703870\ttotal: 1.41s\tremaining: 547ms\n",
      "216:\tlearn: 0.6701590\ttotal: 1.41s\tremaining: 540ms\n",
      "217:\tlearn: 0.6700615\ttotal: 1.42s\tremaining: 534ms\n",
      "218:\tlearn: 0.6698384\ttotal: 1.43s\tremaining: 528ms\n",
      "219:\tlearn: 0.6695544\ttotal: 1.43s\tremaining: 521ms\n",
      "220:\tlearn: 0.6693170\ttotal: 1.44s\tremaining: 514ms\n",
      "221:\tlearn: 0.6691462\ttotal: 1.44s\tremaining: 507ms\n",
      "222:\tlearn: 0.6688191\ttotal: 1.45s\tremaining: 500ms\n",
      "223:\tlearn: 0.6684846\ttotal: 1.45s\tremaining: 493ms\n",
      "224:\tlearn: 0.6683718\ttotal: 1.46s\tremaining: 486ms\n",
      "225:\tlearn: 0.6681095\ttotal: 1.47s\tremaining: 480ms\n",
      "226:\tlearn: 0.6678199\ttotal: 1.47s\tremaining: 474ms\n",
      "227:\tlearn: 0.6675496\ttotal: 1.48s\tremaining: 467ms\n",
      "228:\tlearn: 0.6672544\ttotal: 1.48s\tremaining: 460ms\n",
      "229:\tlearn: 0.6670559\ttotal: 1.49s\tremaining: 453ms\n",
      "230:\tlearn: 0.6666793\ttotal: 1.49s\tremaining: 446ms\n",
      "231:\tlearn: 0.6665645\ttotal: 1.5s\tremaining: 440ms\n",
      "232:\tlearn: 0.6663121\ttotal: 1.51s\tremaining: 433ms\n",
      "233:\tlearn: 0.6660358\ttotal: 1.51s\tremaining: 427ms\n",
      "234:\tlearn: 0.6658186\ttotal: 1.52s\tremaining: 420ms\n",
      "235:\tlearn: 0.6654950\ttotal: 1.52s\tremaining: 414ms\n",
      "236:\tlearn: 0.6653635\ttotal: 1.53s\tremaining: 407ms\n",
      "237:\tlearn: 0.6651501\ttotal: 1.54s\tremaining: 400ms\n",
      "238:\tlearn: 0.6649676\ttotal: 1.54s\tremaining: 394ms\n",
      "239:\tlearn: 0.6647443\ttotal: 1.55s\tremaining: 387ms\n",
      "240:\tlearn: 0.6646156\ttotal: 1.55s\tremaining: 380ms\n",
      "241:\tlearn: 0.6644916\ttotal: 1.56s\tremaining: 374ms\n",
      "242:\tlearn: 0.6644134\ttotal: 1.57s\tremaining: 367ms\n",
      "243:\tlearn: 0.6642222\ttotal: 1.57s\tremaining: 362ms\n",
      "244:\tlearn: 0.6639145\ttotal: 1.58s\tremaining: 355ms\n",
      "245:\tlearn: 0.6636801\ttotal: 1.59s\tremaining: 348ms\n",
      "246:\tlearn: 0.6632706\ttotal: 1.59s\tremaining: 342ms\n",
      "247:\tlearn: 0.6631025\ttotal: 1.6s\tremaining: 335ms\n",
      "248:\tlearn: 0.6629269\ttotal: 1.6s\tremaining: 329ms\n",
      "249:\tlearn: 0.6627558\ttotal: 1.61s\tremaining: 322ms\n",
      "250:\tlearn: 0.6625230\ttotal: 1.62s\tremaining: 316ms\n",
      "251:\tlearn: 0.6622841\ttotal: 1.62s\tremaining: 309ms\n",
      "252:\tlearn: 0.6620956\ttotal: 1.63s\tremaining: 303ms\n",
      "253:\tlearn: 0.6618617\ttotal: 1.63s\tremaining: 296ms\n",
      "254:\tlearn: 0.6617341\ttotal: 1.64s\tremaining: 289ms\n",
      "255:\tlearn: 0.6615511\ttotal: 1.64s\tremaining: 283ms\n",
      "256:\tlearn: 0.6613594\ttotal: 1.65s\tremaining: 276ms\n",
      "257:\tlearn: 0.6611178\ttotal: 1.66s\tremaining: 270ms\n",
      "258:\tlearn: 0.6608614\ttotal: 1.66s\tremaining: 263ms\n",
      "259:\tlearn: 0.6604988\ttotal: 1.67s\tremaining: 256ms\n",
      "260:\tlearn: 0.6602466\ttotal: 1.67s\tremaining: 250ms\n",
      "261:\tlearn: 0.6599955\ttotal: 1.68s\tremaining: 243ms\n",
      "262:\tlearn: 0.6597054\ttotal: 1.69s\tremaining: 237ms\n",
      "263:\tlearn: 0.6595785\ttotal: 1.69s\tremaining: 231ms\n",
      "264:\tlearn: 0.6593887\ttotal: 1.7s\tremaining: 224ms\n",
      "265:\tlearn: 0.6592600\ttotal: 1.7s\tremaining: 218ms\n",
      "266:\tlearn: 0.6591580\ttotal: 1.71s\tremaining: 211ms\n",
      "267:\tlearn: 0.6589472\ttotal: 1.72s\tremaining: 205ms\n",
      "268:\tlearn: 0.6587035\ttotal: 1.72s\tremaining: 199ms\n",
      "269:\tlearn: 0.6585131\ttotal: 1.73s\tremaining: 192ms\n",
      "270:\tlearn: 0.6582320\ttotal: 1.74s\tremaining: 186ms\n",
      "271:\tlearn: 0.6581307\ttotal: 1.74s\tremaining: 179ms\n",
      "272:\tlearn: 0.6578864\ttotal: 1.75s\tremaining: 173ms\n",
      "273:\tlearn: 0.6577162\ttotal: 1.75s\tremaining: 166ms\n",
      "274:\tlearn: 0.6574203\ttotal: 1.76s\tremaining: 160ms\n",
      "275:\tlearn: 0.6573086\ttotal: 1.76s\tremaining: 153ms\n",
      "276:\tlearn: 0.6570447\ttotal: 1.77s\tremaining: 147ms\n",
      "277:\tlearn: 0.6568172\ttotal: 1.77s\tremaining: 140ms\n",
      "278:\tlearn: 0.6565818\ttotal: 1.78s\tremaining: 134ms\n",
      "279:\tlearn: 0.6564033\ttotal: 1.78s\tremaining: 128ms\n",
      "280:\tlearn: 0.6558969\ttotal: 1.79s\tremaining: 121ms\n",
      "281:\tlearn: 0.6557175\ttotal: 1.8s\tremaining: 115ms\n",
      "282:\tlearn: 0.6554100\ttotal: 1.8s\tremaining: 108ms\n",
      "283:\tlearn: 0.6553040\ttotal: 1.81s\tremaining: 102ms\n",
      "284:\tlearn: 0.6550741\ttotal: 1.82s\tremaining: 95.9ms\n",
      "285:\tlearn: 0.6547515\ttotal: 1.83s\tremaining: 89.5ms\n",
      "286:\tlearn: 0.6545225\ttotal: 1.83s\tremaining: 83.1ms\n",
      "287:\tlearn: 0.6544488\ttotal: 1.84s\tremaining: 76.7ms\n",
      "288:\tlearn: 0.6542965\ttotal: 1.84s\tremaining: 70.2ms\n",
      "289:\tlearn: 0.6539549\ttotal: 1.85s\tremaining: 64ms\n",
      "290:\tlearn: 0.6538154\ttotal: 1.86s\tremaining: 57.6ms\n",
      "291:\tlearn: 0.6536573\ttotal: 1.87s\tremaining: 51.2ms\n",
      "292:\tlearn: 0.6534931\ttotal: 1.88s\tremaining: 44.9ms\n",
      "293:\tlearn: 0.6533516\ttotal: 1.89s\tremaining: 38.5ms\n",
      "294:\tlearn: 0.6532494\ttotal: 1.9s\tremaining: 32.1ms\n",
      "295:\tlearn: 0.6529555\ttotal: 1.9s\tremaining: 25.7ms\n",
      "296:\tlearn: 0.6527301\ttotal: 1.91s\tremaining: 19.3ms\n",
      "297:\tlearn: 0.6526237\ttotal: 1.92s\tremaining: 12.9ms\n",
      "298:\tlearn: 0.6524011\ttotal: 1.92s\tremaining: 6.43ms\n",
      "299:\tlearn: 0.6522955\ttotal: 1.93s\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "model_run.hyper_search('CatBoost', params=CatBoost_params, searcher_kwargs=search_options, set_to_train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot clone object. You should provide an instance of scikit-learn estimator instead of a class.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-2e2264b3c663>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_run\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyper_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'SVM'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSVM_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msearcher_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msearch_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_to_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/Tanzania-Well-Project/ourfunctions.py\u001b[0m in \u001b[0;36mhyper_search\u001b[0;34m(self, name, searcher, params, searcher_kwargs, print, set_to_train)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mX_train_processed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_models\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'preprocessor'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_X_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m         \u001b[0msearch_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_processed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_y_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"For model {name}, {searcher} with{params} produced:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Params: {search_object.best_params_}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    679\u001b[0m         \u001b[0mn_splits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_n_splits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m         \u001b[0mbase_estimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m         parallel = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mclone\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m                 raise TypeError(\"Cannot clone object. \" +\n\u001b[0m\u001b[1;32m     75\u001b[0m                                 \u001b[0;34m\"You should provide an instance of \"\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m                                 \"scikit-learn estimator instead of a class.\")\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot clone object. You should provide an instance of scikit-learn estimator instead of a class."
     ]
    }
   ],
   "source": [
    "model_run.hyper_search('SVM', params=SVM_params, searcher_kwargs=search_options, set_to_train=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "This model has not been fit yet.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-1c350ec21d92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_run\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'log_reg_regularized'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/Tanzania-Well-Project/ourfunctions.py\u001b[0m in \u001b[0;36mtest_model\u001b[0;34m(self, name, X_test, y_test, print)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fit_classifier'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# Should add auto train fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"This model has not been fit yet.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_output'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fit_classifier'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_processed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: This model has not been fit yet."
     ]
    }
   ],
   "source": [
    "model_run.test_model('log_reg_regularized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This ColumnTransformer instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-3a0a172a5201>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_run\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'knn'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/Tanzania-Well-Project/ourfunctions.py\u001b[0m in \u001b[0;36mtest_model\u001b[0;34m(self, name, X_test, y_test, print)\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_models\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m         \u001b[0mX_test_processed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'preprocessor'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fit_classifier'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# Should add auto train fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/compose/_column_transformer.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m         \"\"\"\n\u001b[0;32m--> 573\u001b[0;31m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    574\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_X\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m   1017\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1019\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1020\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFittedError\u001b[0m: This ColumnTransformer instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "model_run.test_model('kNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "root - INFO - RandomFM_default test score: 0.7924579124579124\n"
     ]
    }
   ],
   "source": [
    "model_run.test_model('RandomFM_default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "This model has not been fit yet.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-d30afe5e59ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_run\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DecisionTreesAd'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/Tanzania-Well-Project/ourfunctions.py\u001b[0m in \u001b[0;36mtest_model\u001b[0;34m(self, name, X_test, y_test, print)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fit_classifier'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# Should add auto train fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"This model has not been fit yet.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_output'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fit_classifier'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_processed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: This model has not been fit yet."
     ]
    }
   ],
   "source": [
    "model_run.test_model('DecisionTreesAd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "root - INFO - AdaBoost test score: 0.637979797979798\n"
     ]
    }
   ],
   "source": [
    "model_run.test_model('AdaBoost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "This model has not been fit yet.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-6ad72ea03086>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_run\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GradBoost'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/Tanzania-Well-Project/ourfunctions.py\u001b[0m in \u001b[0;36mtest_model\u001b[0;34m(self, name, X_test, y_test, print)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fit_classifier'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# Should add auto train fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"This model has not been fit yet.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_output'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fit_classifier'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_processed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: This model has not been fit yet."
     ]
    }
   ],
   "source": [
    "model_run.test_model('GradBoost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "This model has not been fit yet.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-07bfa58f8523>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_run\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'XGBoost'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/Tanzania-Well-Project/ourfunctions.py\u001b[0m in \u001b[0;36mtest_model\u001b[0;34m(self, name, X_test, y_test, print)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fit_classifier'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# Should add auto train fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"This model has not been fit yet.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_output'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fit_classifier'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_processed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: This model has not been fit yet."
     ]
    }
   ],
   "source": [
    "model_run.test_model('XGBoost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "root - INFO - CatBoost test score: 0.6808754208754209\n"
     ]
    }
   ],
   "source": [
    "model_run.test_model('CatBoost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "This model has not been fit yet.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-d81cbc218291>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_run\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'SVM'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/Tanzania-Well-Project/ourfunctions.py\u001b[0m in \u001b[0;36mtest_model\u001b[0;34m(self, name, X_test, y_test, print)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fit_classifier'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# Should add auto train fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"This model has not been fit yet.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_output'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fit_classifier'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_processed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: This model has not been fit yet."
     ]
    }
   ],
   "source": [
    "model_run.test_model('SVM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'test_output'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-f0182ab38cf8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_run\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'wednesday_models_graph'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/Tanzania-Well-Project/ourfunctions.py\u001b[0m in \u001b[0;36mplot_models\u001b[0;34m(self, sns_style, sns_context, palette, save)\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0mxticklabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_output'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_style\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msns_style\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Tanzania-Well-Project/ourfunctions.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0mxticklabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_output'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_style\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msns_style\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'test_output'"
     ]
    }
   ],
   "source": [
    "model_run.plot_models(save='wednesday_models_graph')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a8985f70e60044e6b9ee20c3abf47b95903615267cecf7f0794b337aafc6df41"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('learn-env': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
