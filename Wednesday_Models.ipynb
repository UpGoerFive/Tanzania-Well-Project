{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import ourfunctions\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import logging\n",
    "\n",
    "#from sklearnex import patch_sklearn\n",
    "#patch_sklearn(verbose=False)\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler, LabelEncoder, FunctionTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, AdaBoostRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import plot_confusion_matrix, recall_score, accuracy_score, precision_score, f1_score\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImPipeline\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn import svm\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('data/Training-set-values.csv')\n",
    "y = pd.read_csv('data/Training-set-labels.csv')\n",
    "y = pd.DataFrame(LabelEncoder().fit_transform(y.status_group))\n",
    "\n",
    "X['date_recorded'] = pd.to_datetime(X['date_recorded']).astype(np.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Super basic numeric transformer\n",
    "\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[('imputer', SimpleImputer(strategy='median'))]\n",
    ")\n",
    "\n",
    "numeric_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"numeric\", numeric_transformer, make_column_selector(dtype_include=np.number)),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kNearestNeighbors\n",
    "knn = {'classifier': KNeighborsClassifier(n_jobs=3), 'preprocessor': None}\n",
    "\n",
    "# Logistic Regressoion\n",
    "log_reg_basic = {'classifier': LogisticRegression(C=1e6, n_jobs=3), 'preprocessor': None}\n",
    "\n",
    "# Decision Trees\n",
    "DecisionTrees = {'classifier': DecisionTreeClassifier,'preprocessor': None}\n",
    "# Decision Trees - adjusted\n",
    "DecisionTreesAd = {'classifier': DecisionTreeClassifier(criterion=['gini','entropy'], max_depth=[90,100], min_samples_split=[2,3], class_weight=['balaced']),'preprocessor': numeric_preprocessor}\n",
    "\n",
    "# Random Forest with numeric processor\n",
    "RandomFM_basic = {'classifier': RandomForestClassifier(max_depth=20, min_samples_split=4, n_jobs=3), 'preprocessor': numeric_preprocessor}\n",
    "# Random Forest no processor\n",
    "RandomFM_all_cols = {'classifier': RandomForestClassifier(max_depth=20, min_samples_split=4, n_jobs=3), 'preprocessor': None}\n",
    "# Random Forest default\n",
    "# Included for RandomCVSearch later on\n",
    "RandomFM_default = {'classifier': RandomForestClassifier(n_jobs=3), 'preprocessor': None} \n",
    "\n",
    "# Adaptive Boosting\n",
    "AdaBoost = {'classifier': AdaBoostClassifier(), 'preprocessor': numeric_preprocessor}\n",
    "# Gradient Boost\n",
    "GradBoost = {'classifier': GradientBoostingClassifier,'preprocessor': numeric_preprocessor}\n",
    "# XGradient Boosting\n",
    "XGBoost = {'classifier': XGBRegressor(objective='reg:squarederror'), 'preprocessor': numeric_preprocessor}\n",
    "# CatBoost \n",
    "CatBoost = {'classifier': CatBoostClassifier(max_depth=3),'preprocessor': numeric_preprocessor}\n",
    "\n",
    "# Support Vector Machine\n",
    "SVM = {'classifier': svm.SVC,'preprocessor': numeric_preprocessor}\n",
    "\n",
    "models = {'knn': knn, \n",
    "    'log_reg_basic': log_reg_basic, \n",
    "    'DecisionTrees': DecisionTrees,\n",
    "    'DecisionTreesAd': DecisionTreesAd,\n",
    "    'RandomFM_basic': RandomFM_basic, \n",
    "    'RandomFM_all_cols': RandomFM_all_cols, \n",
    "    'RandomFM_default': RandomFM_default,\n",
    "    'AdaBoost': AdaBoost,\n",
    "    'GradBoost': GradBoost,\n",
    "    'XGBoost': XGBoost,\n",
    "    'CatBoost': CatBoost,\n",
    "    \"SVM\": SVM\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_run = ourfunctions.Modeler(models, X=X, y=y)\n",
    "\n",
    "# after the model_run object is created so we can add onto the default preprocessor.\n",
    "log_reg_regularized = {'classifier': LogisticRegression(n_jobs=3), 'preprocessor': model_run.create_default_prep(num_add=[('scaling', StandardScaler())])}\n",
    "model_run.add_model('log_reg_regularized', log_reg_regularized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search parameters and kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "LogRegRCV_params = dict(penalty=['l1', 'l2', 'elasticnet'],\n",
    "                        C=stats.uniform(loc=1, scale=10),\n",
    "                        max_iter=list(range(100,400)))\n",
    "\n",
    "DecisionTree_params = dict(criterion=['gini', 'entropy'],\n",
    "                        max_depth = list(range(20,50)),\n",
    "                        min_samples_split = list(range(2, 10)))\n",
    "\n",
    "RandForestRCV_params = dict(n_estimators=list(range(100,300)),\n",
    "                            criterion=['gini', 'entropy'],\n",
    "                            max_depth = list(range(20,50)),\n",
    "                            min_samples_split = list(range(2, 10)))\n",
    "\n",
    "AdaBoost_params = dict(n_estimators=[10, 50, 100, 500],\n",
    "                        learning_rate=[0.001, 0.01, 0.1, 1.0])\n",
    "\n",
    "GradBoost_params = dict(n_estimators=[10, 30, 100],\n",
    "                    criterion=['friedman_mse', 'squared_error'],\n",
    "                    max_depth=[2, 6, 10],\n",
    "                    min_samples_split=[5, 10],\n",
    "                    min_samples_leaf=[3, 6])\n",
    "\n",
    "XGBoost_params = dict(learning_rate =0.1,\n",
    "                    n_estimators=1000,\n",
    "                    max_depth=4,\n",
    "                    colsample_bytree=0.8,\n",
    "                    objective= 'binary:logistic',\n",
    "                    nthread=4,\n",
    "                    scale_pos_weight=1,\n",
    "                    seed=27)\n",
    "\n",
    "CatBoost_params = dict(max_depth =[3,4,5],\n",
    "                        n_estimators = [100,200,300])\n",
    "\n",
    "SVM_params = dict(C=[0.1,1, 10, 100], \n",
    "                gamma=[1,0.1,0.01,0.001],\n",
    "                kernel=['rbf', 'poly', 'sigmoid'])\n",
    "\n",
    "search_options = {'n_jobs': 3, 'random_state': 9280210, 'n_iter': 20}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_run.hyper_search('log_reg_regularized', params=LogRegRCV_params, searcher_kwargs=search_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/valeriaviscarra/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py:688: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_run.hyper_search('RandomFM_default', params=RandForestRCV_params, searcher_kwargs=search_options, set_to_train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_run.hyper_search('AdaBoost', params=AdaBoost_params, searcher_kwargs=search_options, set_to_train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_run.hyper_search('GradBoost', params=GradBoost_params, searcher_kwargs=search_options, set_to_train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_run.hyper_search('XGBoost', params=XGBoost_params, searcher_kwargs=search_options, set_to_train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_run.hyper_search('CatBoost', params=CatBoost_params, searcher_kwargs=search_options, set_to_train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_run.hyper_search('SVM', params=SVM_params, searcher_kwargs=search_options, set_to_train=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_run.test_model('RandomFM_default')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_run.plot_models(save='wednesday_models_graph')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a8985f70e60044e6b9ee20c3abf47b95903615267cecf7f0794b337aafc6df41"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('learn-env': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
