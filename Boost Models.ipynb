{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import ourfunctions\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "#from sklearnex import patch_sklearn\n",
    "#patch_sklearn(verbose=False)\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler, LabelEncoder, FunctionTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from sklearn.metrics import plot_confusion_matrix, recall_score, accuracy_score, precision_score, f1_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImPipeline\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('data/Training-set-values.csv')\n",
    "y = pd.read_csv('data/Training-set-labels.csv')\n",
    "\n",
    "X['date_recorded'] = pd.to_datetime(X['date_recorded']).astype(np.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Super basic numeric transformer\n",
    "\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[('imputer', SimpleImputer(strategy='median'))]\n",
    ")\n",
    "\n",
    "numeric_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"numeric\", numeric_transformer, make_column_selector(dtype_include=np.number)),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boost\n",
    "GradBoost = {'classifier': GradientBoostingClassifier(),'preprocessor': numeric_preprocessor}\n",
    "GradBoost2 = {'classifier': GradientBoostingClassifier(),'preprocessor': None}\n",
    "GradBoost3 = {'classifier': GradientBoostingClassifier(),'preprocessor': None}\n",
    "# XGradient Boosting\n",
    "XGBoost = {'classifier': XGBRegressor(objective='reg:squarederror'), 'preprocessor': numeric_preprocessor}\n",
    "# CatBoost\n",
    "CatBoost = {'classifier': CatBoostClassifier(max_depth=3),'preprocessor': numeric_preprocessor}\n",
    "\n",
    "\n",
    "\n",
    "models = {'GradientBoost': GradBoost,\n",
    "    'GradientBoost2': GradBoost2,\n",
    "    'GradientBoost3': GradBoost3,\n",
    "    'XGBoost': XGBoost,\n",
    "    'CatBoost': CatBoost\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_run = ourfunctions.Modeler(models, X=X, y=y)\n",
    "\n",
    "# after the model_run object is created so we can add onto the default preprocessor.\n",
    "log_reg_regularized = {'classifier': LogisticRegression(n_jobs=3), 'preprocessor': model_run.create_default_prep(num_add=[('scaling', StandardScaler())])}\n",
    "model_run.add_model('log_reg_regularized', log_reg_regularized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search parameters and kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GradBoost_params = dict(n_estimators=np.array(range(100, 400)),\n",
    "                    criterion=['friedman_mse', 'squared_error'],\n",
    "                    max_depth=np.array(range(2, 10)),\n",
    "                    min_samples_split=np.array(range(2, 10)),\n",
    "                    min_samples_leaf=np.array(range(1, 10)),\n",
    "                    learning_rate=stats.uniform(loc=0.01, scale=1))\n",
    "\n",
    "GradBoost3_params = dict(n_estimators=np.array(range(200, 1000)),\n",
    "                    criterion=['friedman_mse', 'squared_error'],\n",
    "                    max_depth=np.array(range(2, 10)),\n",
    "                    min_samples_split=np.array(range(2, 10)),\n",
    "                    min_samples_leaf=np.array(range(1, 10)),\n",
    "                    learning_rate=stats.uniform(loc=0.001, scale=1))\n",
    "\n",
    "XGBoost_params = dict(learning_rate =stats.uniform(loc=0.1, scale=0.1),\n",
    "                    n_estimators=np.array(range(100,1200)),\n",
    "                    max_depth=np.array(range(4,30)))\n",
    "\n",
    "CatBoost_params = dict(max_depth =[3,4,5],\n",
    "                         n_estimators = [100,200,300])\n",
    "\n",
    "search_options = {'n_jobs': 3, 'random_state': 9280210, 'n_iter': 20}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_run.hyper_search('GradientBoost', params=GradBoost_params, searcher_kwargs=search_options, set_to_train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_run.hyper_search('Gradient2', params=GradBoost_params, searcher_kwargs=search_options, set_to_train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_run.hyper_search('Gradient3', params=GradBoost3_params, searcher_kwargs=search_options, set_to_train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_run.hyper_search('XGBoost', params=XGBoost_params, searcher_kwargs=search_options, set_to_train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_run.hyper_search('CatBoost', params=CatBoost_params, searcher_kwargs=search_options, set_to_train=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_run.test_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_run.plot_models(save='boost_models_graph')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_run.model_evaluation('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_kwargs = dict(n_repeats=10, n_jobs=3)\n",
    "model_run.permutation_importance('', perm_kwargs=importance_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_run.model_evaluation('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_kwargs = dict(n_repeats=10, n_jobs=3)\n",
    "model_run.permutation_importance('', perm_kwargs=importance_kwargs)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a8985f70e60044e6b9ee20c3abf47b95903615267cecf7f0794b337aafc6df41"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('learn-env': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
