{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import logging\n",
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('data/Training-set-values.csv')\n",
    "y = pd.read_csv('data/Training-set-labels.csv')\n",
    "\n",
    "X['date_recorded'] = pd.to_datetime(X['date_recorded'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state = 829941045)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                           0\n",
       "amount_tsh                   0\n",
       "date_recorded                0\n",
       "funder                    3635\n",
       "gps_height                   0\n",
       "installer                 3655\n",
       "longitude                    0\n",
       "latitude                     0\n",
       "wpt_name                     0\n",
       "num_private                  0\n",
       "basin                        0\n",
       "subvillage                 371\n",
       "region                       0\n",
       "region_code                  0\n",
       "district_code                0\n",
       "lga                          0\n",
       "ward                         0\n",
       "population                   0\n",
       "public_meeting            3334\n",
       "recorded_by                  0\n",
       "scheme_management         3877\n",
       "scheme_name              28166\n",
       "permit                    3056\n",
       "construction_year            0\n",
       "extraction_type              0\n",
       "extraction_type_group        0\n",
       "extraction_type_class        0\n",
       "management                   0\n",
       "management_group             0\n",
       "payment                      0\n",
       "payment_type                 0\n",
       "water_quality                0\n",
       "quality_group                0\n",
       "quantity                     0\n",
       "quantity_group               0\n",
       "source                       0\n",
       "source_type                  0\n",
       "source_class                 0\n",
       "waterpoint_type              0\n",
       "waterpoint_type_group        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_cols = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "cat_cols = X.select_dtypes(exclude=['int64', 'float64']).columns\n",
    "\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[('imputer', SimpleImputer(strategy='median'))]\n",
    ")\n",
    "\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[('imputer', SimpleImputer(strategy='constant', fill_value='Missing'))]\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"numeric\", numeric_transformer, num_cols),\n",
    "        (\"categorical\", categorical_transformer, cat_cols)\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Modeler:\n",
    "    \"\"\"\n",
    "    Modeling pipeline. It has basic defaults and can accept new models and transformers.\n",
    "    Models should be added in the form of:\n",
    "\n",
    "    {'classifier': <classifier>,\n",
    "     'preprocessor': <preprocessor>}\n",
    "\n",
    "    preprocessor can be None if the default preprocessor is acceptable. This class also\n",
    "    logs model output to a default model-run.log file.\n",
    "    \"\"\"\n",
    "    def __init__(self, models={}, num=numeric_transformer, cat=categorical_transformer, prep=preprocessor, X=None, y= None, log='model-run.log'):\n",
    "        self._models=models\n",
    "        self._numeric=num\n",
    "        self._categorical=cat\n",
    "        self._preprocessor=prep\n",
    "        self._log = log\n",
    "        logging.basicConfig(filename=log, level=logging.DEBUG)\n",
    "        if X and y:\n",
    "            self._X_train, self._X_test, self._y_train, self._y_test = train_test_split(X, y, test_size=0.25, random_state = 829941045)\n",
    "        else:\n",
    "            self._X_train, self._X_test, self._y_train, self._y_test = None, None, None, None\n",
    "            \n",
    "\n",
    "    def add_model(self, name, model):\n",
    "        self._models[name] = model\n",
    "        self._models[name]['cv_output'] = None\n",
    "        self._models[name]['fit_classifier'] = None\n",
    "        self._models[name]['time_ran'] = None\n",
    "\n",
    "    def change_prep(self, name, prep):\n",
    "        self._models[name]['preprocessor'] = prep\n",
    "\n",
    "    def show_model(self, name):\n",
    "        print(f\"{name}: {self._models[name]}\")\n",
    "\n",
    "    def train_model(self, name, X_train=None, y_train=None, print=True):\n",
    "        if not X_train:\n",
    "            X_train = self._X_train\n",
    "        if not y_train:\n",
    "            y_train = self._y_train\n",
    "        model = self._models[name]\n",
    "        X_train_processed = model['preprocessor'].fit_transform(X_train)\n",
    "        model['fit_classifier'] = model['classifier'].fit(X_train_processed, y_train)\n",
    "\n",
    "    def train_all(self, X_train, y_train, print=False):\n",
    "        pass\n",
    "\n",
    "    def test_model(self, name, X_test, y_test, print=True):\n",
    "        pass\n",
    "\n",
    "    def test_all(self, X_test, y_test, print=False):\n",
    "        pass\n",
    "\n",
    "    def plot_models(self):\n",
    "        \"\"\"Skylar slide style.\"\"\"\n",
    "        pass\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a8985f70e60044e6b9ee20c3abf47b95903615267cecf7f0794b337aafc6df41"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('learn-env': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
